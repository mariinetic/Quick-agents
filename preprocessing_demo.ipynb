{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5410a7b9",
   "metadata": {},
   "source": [
    "# Data Preprocessing Demo ‚Äî \"Glow Up\" Edition ‚ú®üßº\n",
    "**Language:** English  \n",
    "**Vibe:** Fun, Gen Z-friendly, and ready to present.\n",
    "\n",
    "This notebook shows a small end-to-end demo of preprocessing: importing *dirty* data, cleaning & imputing, scaling numeric features, encoding categorical features, and visualizing _before vs after_.  \n",
    "Run cells sequentially. Let's make these messy data look *chef's kiss* üòéüî•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a0fb2",
   "metadata": {},
   "source": [
    "## 1) Create a small 'dirty' dataset\n",
    "We'll intentionally make mistakes: missing values, bad numeric outliers, negative salary, and a weird category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c88db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small dirty DataFrame\n",
    "data = {\n",
    "    'Age': [25, np.nan, 47, 51, 23, 999, 35, np.nan, 28],\n",
    "    'Salary': [5000, 6000, np.nan, 8000, 12000, 30000, -100, 7000, 6500],\n",
    "    'Gender': ['M', 'F', 'F', np.nan, 'M', 'Other', 'F', 'F', 'M'],\n",
    "    'City': ['SP', 'RJ', 'SP', 'MG', np.nan, 'RJ', 'RS', 'SP', 'RJ']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print('üîπ Original dirty data (first rows):')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028921c",
   "metadata": {},
   "source": [
    "### Visual: Missing values heatmap (before)\n",
    "White = missing, dark = present. We'll use a matplotlib imshow for a clean look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cebb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of missing values (before)\n",
    "plt.figure(figsize=(6,2.5))\n",
    "plt.imshow(df.isnull().T, aspect='auto', interpolation='nearest')\n",
    "plt.yticks(range(df.shape[1]), df.columns)\n",
    "plt.xticks(range(df.shape[0]), range(df.shape[0]))\n",
    "plt.title('Missing values (before)')\n",
    "plt.xlabel('Row index')\n",
    "plt.colorbar(label='missing (True=1, False=0)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a2202",
   "metadata": {},
   "source": [
    "## 2) Cleaning & Imputation\n",
    "Steps:\n",
    "- Fix obvious outliers (Age > 100 ‚Üí NaN)\n",
    "- Fix Salary negative or extremely large values ‚Üí NaN\n",
    "- Impute numeric features (median/mean)\n",
    "- Impute categorical features (mode / placeholder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e573890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning outliers\n",
    "df_clean = df.copy()\n",
    "df_clean['Age'] = df_clean['Age'].apply(lambda x: np.nan if x>100 else x)\n",
    "df_clean['Salary'] = df_clean['Salary'].apply(lambda x: np.nan if (x is not None and (x<0 or x>20000)) else x)\n",
    "\n",
    "# Impute\n",
    "df_clean['Age'].fillna(df_clean['Age'].median(), inplace=True)\n",
    "df_clean['Salary'].fillna(df_clean['Salary'].mean(), inplace=True)\n",
    "df_clean['Gender'].fillna(df_clean['Gender'].mode()[0], inplace=True)\n",
    "df_clean['City'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print('üßΩ After cleaning & imputation:')\n",
    "display(df_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec8c25",
   "metadata": {},
   "source": [
    "### Visual: Missing values heatmap (after)\n",
    "All NaNs should be handled ‚Äî watch the heatmap glow up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ceef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap after\n",
    "plt.figure(figsize=(6,2.5))\n",
    "plt.imshow(df_clean.isnull().T, aspect='auto', interpolation='nearest')\n",
    "plt.yticks(range(df_clean.shape[1]), df_clean.columns)\n",
    "plt.xticks(range(df_clean.shape[0]), range(df_clean.shape[0]))\n",
    "plt.title('Missing values (after)')\n",
    "plt.xlabel('Row index')\n",
    "plt.colorbar(label='missing (True=1, False=0)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0a799",
   "metadata": {},
   "source": [
    "## 3) Scaling numeric features\n",
    "We'll standardize Age and Salary (mean=0, std=1) using `StandardScaler`. This is necessary for many ML models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = df_clean.copy()\n",
    "df_scaled[['Age','Salary']] = scaler.fit_transform(df_scaled[['Age','Salary']])\n",
    "\n",
    "print('üìè After scaling (first rows):')\n",
    "display(df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21dfad",
   "metadata": {},
   "source": [
    "## 4) Encoding categorical features\n",
    "We'll convert `Gender` and `City` to numeric using one-hot encoding (drop_first=True to avoid redundancy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec863f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.get_dummies(df_scaled, columns=['Gender','City'], drop_first=True)\n",
    "print('üí° Final dataset ready for modeling (first rows):')\n",
    "display(df_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7e546",
   "metadata": {},
   "source": [
    "## 5) Before vs After distributions\n",
    "We'll show histograms of numeric columns before cleaning and after scaling to highlight the change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms: Age and Salary before cleaning\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df['Age'].dropna(), bins=6)\n",
    "plt.title('Age (original)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df['Salary'].loc[df['Salary'].notnull()], bins=6)\n",
    "plt.title('Salary (original)')\n",
    "plt.show()\n",
    "\n",
    "# Histograms after scaling (Age and Salary are standardized)\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df_scaled['Age'], bins=6)\n",
    "plt.title('Age (scaled)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df_scaled['Salary'], bins=6)\n",
    "plt.title('Salary (scaled)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d773ffb",
   "metadata": {},
   "source": [
    "## Wrap-up & Presentation tips\n",
    "- Show **before vs after** tables and heatmaps ‚Äî people love the visual glow-up.\n",
    "- Explain why you chose median/mean/mode for imputation.\n",
    "- Mention why scaling matters (distance-based models, gradient descent, etc).\n",
    "- Keep it short and spicy: 1 slide for problems, 1 slide for each step, 1 slide with final dataset.\n",
    "\n",
    "Ok go slay that demo! üòé‚ú®\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
